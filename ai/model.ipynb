{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5870336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model_definition import LSTMClassifier, CNN1DClassifier, MLPClassifier                 # Load models\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b257fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA INGESTION FROM CSV\n",
    "\n",
    "class SensorDataset(Dataset):\n",
    "    def __init__(self, csv_dir, labels_dict, statistical_processing=False):\n",
    "        self.csv_dir = csv_dir\n",
    "        self.labels_dict = labels_dict\n",
    "        self.file_list = [f for f in os.listdir(csv_dir) if f in self.labels_dict]\n",
    "        self.statistical_processing = statistical_processing\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        file_path = os.path.join(self.csv_dir, file_name)\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        features = df.iloc[:, 1:].values\n",
    "        if self.statistical_processing:\n",
    "            # Process for each feature -> x3\n",
    "            mean_cols = np.tile(np.mean(features, axis=0), (25, 1))\n",
    "            std_cols = np.tile(np.std(features, axis=0), (25, 1))\n",
    "            features = np.hstack([features, mean_cols, std_cols])\n",
    "            \n",
    "        features = torch.tensor(features, dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels_dict[file_name], dtype=torch.float32)\n",
    "\n",
    "        return features, label\n",
    "\n",
    "def create_dataloader(dataset, csv_dir, labels_dict, statistical_processing=False, batch_size=4):\n",
    "    data = dataset(csv_dir, labels_dict, statistical_processing)\n",
    "    return DataLoader(data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7011310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 42.7449\n",
      "Epoch 2/20 - Loss: 25.5671\n",
      "Epoch 3/20 - Loss: 15.2530\n",
      "Epoch 4/20 - Loss: 11.7506\n",
      "Epoch 5/20 - Loss: 8.2157\n",
      "Epoch 6/20 - Loss: 7.9120\n",
      "Epoch 7/20 - Loss: 8.8302\n",
      "Epoch 8/20 - Loss: 8.3544\n",
      "Epoch 9/20 - Loss: 6.8826\n",
      "Epoch 10/20 - Loss: 4.8389\n",
      "Epoch 11/20 - Loss: 4.9417\n",
      "Epoch 12/20 - Loss: 3.6754\n",
      "Epoch 13/20 - Loss: 1.7469\n",
      "Epoch 14/20 - Loss: 3.0781\n",
      "Epoch 15/20 - Loss: 3.2896\n",
      "Epoch 16/20 - Loss: 2.6153\n",
      "Epoch 17/20 - Loss: 2.7862\n",
      "Epoch 18/20 - Loss: 3.1733\n",
      "Epoch 19/20 - Loss: 3.3038\n",
      "Epoch 20/20 - Loss: 3.2444\n"
     ]
    }
   ],
   "source": [
    "### TRAINING\n",
    "\n",
    "def train_model(dataloader, model, criterion, optimiser, epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_features, batch_labels in dataloader:\n",
    "            if isinstance(model, CNN1DClassifier):\n",
    "                batch_features = batch_features.transpose(1, 2)\n",
    "            batch_features = batch_features.to(device)\n",
    "            batch_labels = batch_labels.to(device).long()\n",
    "            \n",
    "            optimiser.zero_grad()\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # return loss.item()         # For Optuna, eventually\n",
    "\n",
    "statistical_processing = False\n",
    "data_folder_path = \"data/dummy/dataset\"\n",
    "with open(\"data/dummy/dataset/labels.json\", \"r\") as f:\n",
    "    labels_dict = json.load(f)\n",
    "dataloader = create_dataloader(SensorDataset, data_folder_path, labels_dict, statistical_processing, batch_size=5)\n",
    "\n",
    "# model = LSTMClassifier(input_size=8*3 if statistical_processing else 8, hidden_size=64, num_layers=2, num_classes=8)\n",
    "model = CNN1DClassifier(input_size=8, num_classes=8)\n",
    "# model = MLPClassifier(input_size=8, num_classes=8)\n",
    "\n",
    "lr = 0.001\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(model.parameters(), lr)\n",
    "\n",
    "train_model(dataloader, model, criterion, optimiser, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaef8af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "### PREDICTION AND EVALUATION\n",
    "\n",
    "def get_features_from_csv(file_path, statistical_processing=False):\n",
    "    df = pd.read_csv(file_path)\n",
    "    features = df.iloc[:, 1:].values\n",
    "\n",
    "    if statistical_processing:\n",
    "        mean_cols = np.tile(np.mean(features, axis=0), (25, 1))\n",
    "        std_cols = np.tile(np.std(features, axis=0), (25, 1))\n",
    "        features = np.hstack([features, mean_cols, std_cols])\n",
    "\n",
    "    return features\n",
    "\n",
    "def predict_csv(model, features):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if isinstance(model, CNN1DClassifier):      # TODO: test if moving it down here works\n",
    "        features = features.transpose()\n",
    "    input_tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        \n",
    "        pred_class = torch.argmax(probs, dim=1).item()\n",
    "        confidence = torch.max(probs).item()\n",
    "        \n",
    "    return pred_class, confidence\n",
    "\n",
    "def evaluate_folder(model, folder_path, labels_dict, statistical_processing=False):       \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for file_name, label in labels_dict.items():\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        features = get_features_from_csv(file_path, statistical_processing)\n",
    "\n",
    "        pred, confidence = predict_csv(model, features)\n",
    "        y_true.append(label)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred, labels=list(range(8)))\n",
    "    report = classification_report(y_true, y_pred, labels=list(range(8)), zero_division=0)\n",
    "    \n",
    "    return accuracy, conf_matrix, report\n",
    "\n",
    "acc, cm, report = evaluate_folder(model, data_folder_path, labels_dict, statistical_processing)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b5f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPORT MODEL\n",
    "\n",
    "def export_model(model):\n",
    "    model.eval()\n",
    "    torch.save(model.state_dict(), \"cnn_weights.pth\")\n",
    "\n",
    "export_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
