{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5870336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b257fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA INGESTION\n",
    "\n",
    "class SensorDataset(Dataset):\n",
    "    def __init__(self, csv_dir, label_file):\n",
    "        self.csv_dir = csv_dir\n",
    "        with open(label_file, 'r') as f:\n",
    "            self.labels_dict = json.load(f)\n",
    "        self.file_list = [f for f in os.listdir(csv_dir) if f in self.labels_dict]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        file_path = os.path.join(self.csv_dir, file_name)\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        features = df.iloc[:, 1:].values\n",
    "        features = torch.tensor(features, dtype=torch.float32)\n",
    "        \n",
    "        label = self.labels_dict[file_name]\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        return features, label\n",
    "\n",
    "def create_dataloader(csv_dir, label_file, batch_size=4):\n",
    "    \"\"\"\n",
    "    Create dataloader for features (folder of CSVs) and labels (single JSON file).\n",
    "    \"\"\"\n",
    "    dataset = SensorDataset(csv_dir, label_file)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "519743d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODELS\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 3-layer MLP\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, dropout_rate=0.2):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "# 1D CNN\n",
    "class CNN1DClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(CNN1DClassifier, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_size, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv_block(x)\n",
    "        x = x.squeeze(-1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4cd8b59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 17.7142\n",
      "Epoch 2/20 - Loss: 3.0993\n",
      "Epoch 3/20 - Loss: 3.9404\n",
      "Epoch 4/20 - Loss: 1.9289\n",
      "Epoch 5/20 - Loss: 2.4119\n",
      "Epoch 6/20 - Loss: 2.1205\n",
      "Epoch 7/20 - Loss: 1.4929\n",
      "Epoch 8/20 - Loss: 1.1879\n",
      "Epoch 9/20 - Loss: 1.4211\n",
      "Epoch 10/20 - Loss: 1.5772\n",
      "Epoch 11/20 - Loss: 1.0593\n",
      "Epoch 12/20 - Loss: 1.1646\n",
      "Epoch 13/20 - Loss: 1.0457\n",
      "Epoch 14/20 - Loss: 1.7416\n",
      "Epoch 15/20 - Loss: 0.9086\n",
      "Epoch 16/20 - Loss: 1.3006\n",
      "Epoch 17/20 - Loss: 0.8041\n",
      "Epoch 18/20 - Loss: 0.7933\n",
      "Epoch 19/20 - Loss: 0.6908\n",
      "Epoch 20/20 - Loss: 0.8727\n"
     ]
    }
   ],
   "source": [
    "### TRAINING\n",
    "\n",
    "def train_model(dataloader, model, criterion, optimiser, epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_features, batch_labels in dataloader:\n",
    "            batch_features = batch_features.to(device)\n",
    "            batch_labels = batch_labels.to(device).long()\n",
    "            \n",
    "            optimiser.zero_grad()\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # return loss.item()         # For Optuna, eventually\n",
    "\n",
    "dataloader = create_dataloader(\"data/dummy/dataset\", \"data/dummy/dataset/labels.json\", batch_size=3)\n",
    "# model = LSTMClassifier(input_size=8, hidden_size=64, num_layers=2, num_classes=8)\n",
    "# model = MLPClassifier(input_size=8, num_classes=8)\n",
    "model = CNN1DClassifier(input_size=8, num_classes=8)\n",
    "\n",
    "lr = 0.001\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(model.parameters(), lr)\n",
    "\n",
    "train_model(dataloader, model, criterion, optimiser, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eaef8af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 1, 4, 6, 7]\n",
      "[7, 1, 4, 7, 7]\n",
      "0.6\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 2]\n",
      " [0 0 0 0 0 0 0 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.33      1.00      0.50         1\n",
      "\n",
      "   micro avg       0.60      0.60      0.60         5\n",
      "   macro avg       0.29      0.38      0.31         5\n",
      "weighted avg       0.47      0.60      0.50         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### PREDICTION AND EVALUATE\n",
    "\n",
    "def get_features_from_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    features = df.iloc[:, 1:].values\n",
    "    return features\n",
    "\n",
    "def predict_csv(model, features):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    input_tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        \n",
    "        pred_class = torch.argmax(probs, dim=1).item()\n",
    "        confidence = torch.max(probs).item()\n",
    "        \n",
    "    return pred_class, confidence\n",
    "\n",
    "def evaluate_folder(model, folder_path, label_path):\n",
    "    with open(label_path, 'r') as f:\n",
    "        ground_truth = json.load(f)\n",
    "        \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for file_name, label in ground_truth.items():\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        features = get_features_from_csv(file_path)\n",
    "\n",
    "        pred, confidence = predict_csv(model, features)\n",
    "        y_true.append(label)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred, labels=list(range(8)))\n",
    "    report = classification_report(y_true, y_pred, labels=list(range(8)), zero_division=0)\n",
    "    \n",
    "    return y_true, y_pred, accuracy, conf_matrix, report\n",
    "\n",
    "folder_path = \"data/dummy/dataset\"\n",
    "for item in evaluate_folder(model, folder_path, \"data/dummy/dataset/labels.json\"):\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
