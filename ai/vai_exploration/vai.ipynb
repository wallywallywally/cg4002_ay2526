{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd45ec3",
   "metadata": {},
   "source": [
    "### Vitis AI route\n",
    "\n",
    "1. Start up Docker engine in Windows\n",
    "2. In WSL, copy and ```cd wsl_vitis```\n",
    "3. ```docker run -it -v $(pwd):/vitis_ai_home xilinx/vitis-ai-pytorch-cpu:latest```\n",
    "4. ```cd /vitis_ai_home```\n",
    "5. Quantise: ```python quantiser.py```\n",
    "6. Compile:\n",
    "\n",
    "    ```\n",
    "    vai_c_xir \\\n",
    "        --xmodel  quantize_result/CNN1DClassifier_int.xmodel \\\n",
    "        --arch    /opt/vitis_ai/compiler/arch/DPUCZDX8G/ZCU102/arch.json \\\n",
    "        --net_name cnn \\\n",
    "        --output_dir compiled_model\n",
    "    ```\n",
    "7. Transfer files from local to Ultra96:\n",
    "    ```scp [local file] xilinx@makerslab-fpga-17.ddns.comp.nus.edu.sg:/home/b10```\n",
    "8. Get DPU-PYNQ files\n",
    "    ```wget https://raw.githubusercontent.com/Xilinx/DPU-PYNQ/master/pynq_dpu/dpu.py```\n",
    "    ```curl -L \"https://www.xilinx.com/bin/public/openDownload?filename=pynqdpu.dpu.Ultra96v2.2.5.0.hwh\" -o dpu.hwh```\n",
    "    ```curl -L \"https://www.xilinx.com/bin/public/openDownload?filename=pynqdpu.dpu.Ultra96v2.2.5.0.xclbin\" -o dpu.xclbin```\n",
    "\n",
    "#### Verdict\n",
    "- Vitis AI does not let us evaluate area\n",
    "- DPU setup is painful\n",
    "=> Vitis HLS + Vivado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771da0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VITIS AI ROUTE\n",
    "\"\"\"\n",
    "Copy wsl_vitis into WSL:\n",
    "> cp -r /mnt/c/Users/Willson/Desktop/Y4S2/CG4002\\ -\\ CEG\\ Capstone/cg4002_ay2526/ai/wsl_vitis/ .\n",
    "\"\"\"\n",
    "\n",
    "def export_model(model):\n",
    "    model.eval()\n",
    "    torch.save(model.state_dict(), \"wsl_vitis/cnn_weights.pth\")\n",
    "\n",
    "# For Kaggle data\n",
    "def get_calibration_data_kaggle(folder_path, labels_dict, num_samples=100):\n",
    "    all_windows = []\n",
    "    \n",
    "    # 1 file = many samples\n",
    "    files_per_label = max(1, num_samples // (len(labels_dict) * 2)) \n",
    "    label_counts = {label: 0 for label in set(labels_dict.values())}\n",
    "    \n",
    "    for file_name, label in labels_dict.items():\n",
    "        if label_counts[label] >= files_per_label:\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # For 1D-CNN\n",
    "        windows = get_windows_from_csv(file_path)\n",
    "        windows = windows.transpose(1, 2)\n",
    "        \n",
    "        all_windows.append(windows)\n",
    "        label_counts[label] += 1\n",
    "        \n",
    "        if sum(w.shape[0] for w in all_windows) >= num_samples:\n",
    "            break\n",
    "\n",
    "    calib_tensor = torch.cat(all_windows, dim=0)[:num_samples]\n",
    "    np.save(\"wsl_vitis/calibration_data.npy\", calib_tensor.numpy())\n",
    "\n",
    "def extract_test_samples(csv_dir, labels_dict, output_dir=\"vai_kaggle_test\", num_to_extract=5, window_size=25, statistical_processing=False):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    count = 0\n",
    "    for file_name, label in labels_dict.items():\n",
    "        if count >= num_to_extract: break\n",
    "        \n",
    "        file_path = os.path.join(csv_dir, file_name)\n",
    "        if not os.path.exists(file_path): continue\n",
    "\n",
    "        # 1. Load and slice exactly like your Dataset class\n",
    "        df = pd.read_csv(file_path)\n",
    "        x = torch.tensor(df.iloc[:, 1:].values, dtype=torch.float32) # [T, 44]\n",
    "        T, F = x.shape\n",
    "\n",
    "        # Handle short CSVs\n",
    "        if T < window_size:\n",
    "            pad = torch.zeros(window_size - T, F)\n",
    "            window = torch.cat([x, pad], dim=0)\n",
    "        else:\n",
    "            # Just take the first window for testing\n",
    "            window = x[0:window_size] \n",
    "\n",
    "        # 2. Apply the Statistical Processing (132 features)\n",
    "        if statistical_processing:\n",
    "            w_mean = window.mean(dim=0)\n",
    "            w_std = window.std(dim=0)\n",
    "            mean_feat = w_mean.unsqueeze(0).expand(window_size, -1)\n",
    "            std_feat = w_std.unsqueeze(0).expand(window_size, -1)\n",
    "            window = torch.cat([window, mean_feat, std_feat], dim=-1)\n",
    "\n",
    "        # 3. Transpose for the CNN (Hardware expects [Channels, Length])\n",
    "        # If your model expects [1, 132, 25], transpose here:\n",
    "        final_sample = window.numpy().T # Result: [132, 25]\n",
    "\n",
    "        # 4. Save as .npy for easy loading on FPGA\n",
    "        save_path = os.path.join(output_dir, f\"sample_class{label}_{count}.npy\")\n",
    "        np.save(save_path, final_sample)\n",
    "        print(f\"Saved: {save_path} | Shape: {final_sample.shape}\")\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "# export_model(model_kaggle)\n",
    "# get_calibration_data_kaggle(imu_data_path, labels_kaggle)\n",
    "extract_test_samples(imu_data_path, labels_kaggle)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
